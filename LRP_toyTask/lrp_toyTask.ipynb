{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79000, 5, 2)\n",
      "(20000, 5, 2)\n",
      "(1000, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "import generate_data\n",
    "train,validation,test,cfg= generate_data.generate_data(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device =\"cpu\"\n",
    "#print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import utils_data as ud\n",
    "test_set = ud.Dataset(test[0],test[1],test[2])\n",
    "#testloader = DataLoader(test_set, batch_size=config.batch_size, drop_last = True, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../LRP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_model as um\n",
    "\n",
    "loading_path='model/best_checkpoint1'\n",
    "wi_tuples,wh_tuples,bi_tuples,bh_tuples,wl,bl= um.model_parameters(loading_path,device,cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=um.load_model(cfg,device,loading_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): RNNEncoder(\n",
       "    (rnn_layer): GRU(2, 128, num_layers=2, batch_first=True)\n",
       "  )\n",
       "  (decoder_cell): DecoderCell(\n",
       "    (decoder_rnn_cell): GRU(3, 128, num_layers=2, batch_first=True)\n",
       "    (out1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (out2): Linear(in_features=128, out_features=1, bias=False)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3.5000],\n",
      "         [3.5000],\n",
      "         [2.5000]]], dtype=torch.float64)\n",
      ".....\n",
      "tensor([[[3.5109],\n",
      "         [3.5185],\n",
      "         [2.4903]]], dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tpoint=test_set[14]\n",
    "\n",
    "# tensors\n",
    "inputp,inputf,labels=torch.tensor(np.expand_dims(tpoint[0],axis=0)),torch.tensor(np.expand_dims(tpoint[1],axis=0)),torch.tensor(np.expand_dims(tpoint[2],axis=0))\n",
    "inputp,inputf,labels = inputp.double(), inputf.double(),labels.double()\n",
    "# Model computations\n",
    "prediction =model.forward(inputp, inputf)\n",
    "print(labels)\n",
    "print('.....')\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lrp_function as lrp\n",
    "\n",
    "len_static=cfg.static_feat_len\n",
    "stat=[]\n",
    "mask=(0,2) ## mask\n",
    "lrp_seq2seq= lrp.lrp_decoder_encoder(cfg,len_static, wi_tuples,wh_tuples,bi_tuples,bh_tuples,\n",
    "                                          wl,bl)\n",
    "\n",
    "## y: output of forward pass LRP\n",
    "## Rxf: relevance scores of input sequence forecast\n",
    "## Rx : relevance scores of input sequence historical\n",
    "## Ry: relevance scores of intermidiate decoder outputs\n",
    "## Rstatic: relevance scores of static input (satation number) \n",
    "y,Rxf,Rx,Ry,Rstatic=lrp_seq2seq.lrp_seq2seq(inputp,inputf,stat,mask,epsilon=0.001,bias_factor=0.0) #set bias_factor to 1 for sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.51249262  1.01607014]\n",
      " [-0.50898511 -0.48943871]\n",
      " [-0.4827934   0.95262141]\n",
      " [-0.49999796  0.        ]\n",
      " [ 1.01315237  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(Rx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.],\n",
      "         [-1., -1.],\n",
      "         [-1.,  2.],\n",
      "         [-1.,  0.],\n",
      "         [ 2.,  0.]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(inputp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  2.06481566],\n",
       "       [ 0.95854343, -0.96348574],\n",
       "       [-0.99003967,  0.        ]], dtype=float128)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rxf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  2.],\n",
       "         [ 1., -1.],\n",
       "         [-1.,  0.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input x Graient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/fe/mirzavandborujeni/anaconda3/envs/myenv/lib/python3.8/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients,Saliency,InputXGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fe/mirzavandborujeni/anaconda3/envs/myenv/lib/python3.8/site-packages/captum/_utils/gradient.py:56: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/fe/mirzavandborujeni/anaconda3/envs/myenv/lib/python3.8/site-packages/captum/_utils/gradient.py:56: UserWarning: Input Tensor 1 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_x_gradient = InputXGradient(model)\n",
    "heatmap = input_x_gradient.attribute((inputp,inputf),target=mask[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpg_p=heatmap[0]\n",
    "inpg_f=heatmap[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4931,  0.9828],\n",
       "         [-0.4928, -0.4905],\n",
       "         [-0.4986,  1.0022],\n",
       "         [-0.4979,  0.0000],\n",
       "         [ 1.0030,  0.0000]]], dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpg_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  2.0268],\n",
       "         [ 1.0075, -1.0134],\n",
       "         [-1.0315,  0.0000]]], dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpg_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying integrated gradients on the model with the same data point\n",
    "ig = IntegratedGradients(model)\n",
    "heatmap1  = ig.attribute((inputp,inputf),target=mask[1],n_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "intg_p=heatmap1[0]\n",
    "intg_f=heatmap1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4948,  0.9873],\n",
       "         [-0.4951, -0.4927],\n",
       "         [-0.4999,  1.0023],\n",
       "         [-0.5015,  0.0000],\n",
       "         [ 1.0051,  0.0000]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intg_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  2.0287],\n",
       "         [ 1.0140, -1.0208],\n",
       "         [-1.0368,  0.0000]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intg_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal=Saliency(model)\n",
    "heatmap2  = sal.attribute((inputp,inputf),target=mask[1],abs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_p=heatmap2[0]\n",
    "sa_f=heatmap2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4931, 0.4914],\n",
       "         [0.4928, 0.4905],\n",
       "         [0.4986, 0.5011],\n",
       "         [0.4979, 0.4972],\n",
       "         [0.5015, 0.4999]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0016, 1.0134],\n",
       "         [1.0075, 1.0134],\n",
       "         [1.0315, 1.0363]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
